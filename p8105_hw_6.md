P8105 Homework 6 - UNI: gvs2113
================
2023-11-20

## Problem 1

**Load in the data from github link:**

``` r
url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
homicide_html = read_csv(url)
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

**Creating a `city_state` variable and performing instructed data
cleaning steps.**

``` r
homicide_df = 
  homicide_html |> 
  mutate(
    city_state = paste(city, state, sep = ", "),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1))|> 
  filter(!(city_state %in% c("Dallas, TX", "Pheonix, AZ", "Kansas City, MO", "Tulsa, AL"))) |> 
  filter(victim_race %in% c("White", "Black")) |> 
  mutate(
    victim_age = replace(victim_age, victim_age == "Unknown", NA),
    victim_age = as.numeric(victim_age)
  )
```

**Baltimore, MD logisitic regression**

``` r
baltimore = 
  homicide_df |> 
  filter(city_state == "Baltimore, MD")

b_fit = glm(resolution ~ victim_age + victim_sex + victim_race, data = baltimore) |> 
  broom::tidy() |> 
  mutate(
    OR = exp(estimate),
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |>
  filter(term == "victim_sexMale") |> 
  select(OR, OR_CI_upper, OR_CI_lower) 

b_fit |> 
  knitr::kable(digits = 3)
```

|    OR | OR_CI_upper | OR_CI_lower |
|------:|------------:|------------:|
| 0.816 |       0.868 |       0.766 |

**Logistic Regression for all cities**

``` r
all_city = 
  homicide_df |> 
  nest(data = -city_state) |> 
  mutate(
    model_map = map(data, \(df) glm(resolution ~ victim_age + victim_sex + victim_race, family = binomial(), data = df)),
    tidy_model = map(model_map, broom::tidy)) |> 
  select( -model_map, -data) |> 
  unnest(cols = tidy_model) |> 
  mutate(
    OR = exp(estimate),
    OR_CI_upper = exp(estimate + 1.96 * std.error),
    OR_CI_lower = exp(estimate - 1.96 * std.error)) |>
  filter(term == "victim_sexMale") |> 
  select(city_state, OR, OR_CI_upper, OR_CI_lower) 

all_city |> 
  head(10) |> 
  knitr::kable(digits = 3)
```

| city_state      |    OR | OR_CI_upper | OR_CI_lower |
|:----------------|------:|------------:|------------:|
| Albuquerque, NM | 1.767 |       3.761 |       0.831 |
| Atlanta, GA     | 1.000 |       1.463 |       0.684 |
| Baltimore, MD   | 0.426 |       0.558 |       0.325 |
| Baton Rouge, LA | 0.381 |       0.695 |       0.209 |
| Birmingham, AL  | 0.870 |       1.318 |       0.574 |
| Boston, MA      | 0.674 |       1.276 |       0.356 |
| Buffalo, NY     | 0.521 |       0.935 |       0.290 |
| Charlotte, NC   | 0.884 |       1.403 |       0.557 |
| Chicago, IL     | 0.410 |       0.501 |       0.336 |
| Cincinnati, OH  | 0.400 |       0.677 |       0.236 |

**Plot for OR and CI for each city**

``` r
all_city |> 
  mutate(city_state = fct_reorder(city_state, OR)) |> 
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = OR_CI_lower, ymax = OR_CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  labs(
    title = "Odds Ratios and Confidence Intervals for each City",
    x = "City, State",
    y = "Odds Ratio"
  )
```

<img src="p8105_hw_6_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />

The plot above shows the estimated odds ratio and the 95% confidence
interval associated with the odds of solving homicides for male victims
compared to female victims for all cities contained in the dataset. The
majority of the city’s odds ratios are less than 1. The city with the
lowest odds ratio is New York, NY and the city with the highest odds
ratio is Albuquerque, NM. Albuquerque also has the widest confidence
interval out of all data points. The narrowest interval is for Chicago,
IL.

## Problem 2

**Load in the data:**

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

    ## using cached file: /Users/gracesantos/Library/Caches/org.R-project.R/R/rnoaa/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2023-09-28 10:20:18.929435 (8.524)

    ## file min/max dates: 1869-01-01 / 2023-09-30

**Bootstrapping and Data Wrangling**

``` r
weather_boot = 
  weather_df |> 
  modelr::bootstrap(n = 5000) |>  
  mutate( 
    model = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df)),
    results = map (model, broom::tidy),
    results_2 = map(model, broom::glance)) |> 
  unnest(results) |> 
  select (.id, term, estimate, results_2) |> 
  unnest(results_2) |> 
  select(.id, term, estimate, r.squared) 

weather_boot_pivot = 
  weather_boot |> 
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) |> 
  mutate(log_calc = log(tmin * prcp))
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `log_calc = log(tmin * prcp)`.
    ## Caused by warning in `log()`:
    ## ! NaNs produced

**Plot of distribution of R squared estimate**

``` r
ggplot(data = weather_boot_pivot, aes(x=r.squared)) + geom_density() + 
  labs(
    title = "Distribution of R Squared Estimate",
    x = "R Squared Estimate",
    y = "Count"
  )
```

<img src="p8105_hw_6_files/figure-gfm/unnamed-chunk-8-1.png" width="90%" />

The above plot is meant to show the distribution of the R squared
estimates after each bootstrap. It has a normal shape with a slight left
skew.

**Plot of distribution of log(B1 x B2) estimate**

``` r
ggplot(data = weather_boot_pivot, aes(x=log_calc)) + geom_density() + 
  labs(
    title = "Distribution of log(B1 * B2) Estimate",
    x = "R Squared Estimate",
    y = "Count"
  )
```

    ## Warning: Removed 3361 rows containing non-finite values (`stat_density()`).

<img src="p8105_hw_6_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

The above plot is meant to show the distribution of the log (B1\* B2)
calculations estimates after each bootstrap. It has a more narrow peak
shape with a left skew.

**Confidence Intervals**

``` r
conf_int =   
  weather_boot_pivot |> 
  select(r.squared, log_calc) |> 
  pivot_longer(
    r.squared:log_calc, 
    names_to = "term",
    values_to = "estimate"
  ) |> 
  drop_na() |> 
  group_by(term) |> 
  summarize(
    ci_lower = quantile(estimate, 0.025), 
    ci_upper = quantile(estimate, 0.975))

conf_int |> knitr::kable(digits = 3)
```

| term      | ci_lower | ci_upper |
|:----------|---------:|---------:|
| log_calc  |   -8.982 |   -4.602 |
| r.squared |    0.889 |    0.941 |

Number of NaN values generated when calculating log(B1\*B2)

``` r
n_NaN = weather_boot_pivot |> 
  filter(log_calc == "NaN") |> 
  nrow()
```

There are 3361 NaN results after calculating the log(B1\*B2) estimate.
This resulted from having a negative values for the `prcp` or B2
variable after performing the bootstrapped linear regression.

## Problem 3

**Load in the data:**

``` r
birth_data = read_csv("./data/birthweight.csv") |> 
  janitor::clean_names() |> 
  mutate(
    babysex = case_match(babysex, 
      1 ~ "male", 
      2 ~ "female"), 
    babysex = as.factor(babysex),
    frace = case_match(frace, 
      1 ~ "white",
      2 ~ "black",
      3 ~ "asian",
      4 ~ "puerto_rican",
      8 ~ "other",
      9 ~ "unknown"),
    frace = as.factor(frace),
    malform = case_match(malform, 
      0 ~ "absent", 
      1 ~ "present"), 
    malform =  as.factor(malform),
    mrace = case_match(mrace, 
      1 ~ "white",
      2 ~ "black",
      3 ~ "asian",
      4 ~ "puerto_rican",
      8 ~ "other",
      9 ~ "unknown"),
    mrace = as.factor(mrace)
  )
```

    ## Rows: 4342 Columns: 20
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

For all data, there is a 0 entered for columns: `pnumlbw` (previous
number of low birth weight babies) and `pnumgsa` (number of prior small
for gestational age babies).

**Hypothesized regression model**

``` r
model_0 = lm(bwt ~ momage + delwt, data = birth_data) 

model_0|> 
  broom::tidy() |> 
  select(term, estimate, p.value) |>
  knitr::kable(digits = 3)
```

| term        | estimate | p.value |
|:------------|---------:|--------:|
| (Intercept) | 1867.976 |       0 |
| momage      |   15.200 |       0 |
| delwt       |    6.443 |       0 |

It is hypothesized that the variables that assess the mother’s physical
condition at time of delivery may impact the resulting birth weight of
the baby. Thus, the above linear regression model assess the influence
of the only two variables that are acquired at the time of delivery: the
mother’s age and weight.

**Predictors and Residuals**

``` r
birth_data |> 
  modelr::add_residuals(model_0) |> 
  ggplot(aes(x = momage, y = resid)) + geom_point() + 
  labs(
    title = "Model 0 Residuals of `momage` Variable",
    x = "Mother's Age at Delivery",
    y = "Residuals"
  )
```

<img src="p8105_hw_6_files/figure-gfm/unnamed-chunk-14-1.png" width="90%" />

Since age is a distinct numeric variable, the scatter plot is organized
on vertical lines which represent whole age numbers. There is a wide
spread of residuals between 15-25 years old and then the spread narrows
and becomes more sparse after 30 years old.

``` r
birth_data |> 
  modelr::add_residuals(model_0) |> 
  ggplot(aes(x = delwt, y = resid)) + geom_point() + 
  labs(
    title = "Model 0 Residuals of `delwt` Variable",
    x = "Mother's Weight at Delivery",
    y = "Residuals"
  )
```

<img src="p8105_hw_6_files/figure-gfm/unnamed-chunk-15-1.png" width="90%" />

Since weight is a continuous numeric variable, the scatter plot is less
structured than the one above. The largest density and spread of
residuals is between 100 and 200 lbs and then becomes more sparse and
mostly negative residuals after 200 lbs.

``` r
birth_data |>   
  modelr::add_predictions(model_0) |>
  ggplot(aes(x = momage, y = pred)) + geom_point() + 
  labs(
    title = "Model 0 Predictions of `momage` Variable",
    x = "Mother's Age at Delivery",
    y = "Predictions"
  )
```

<img src="p8105_hw_6_files/figure-gfm/unnamed-chunk-16-1.png" width="90%" />

Since we are again assessing the age variable, this scatter plot is
structured along vertical lines for each whole number age. The
predictions trend upward as mothers age increases, but also decreases in
density and spread. All predictions remain under 4000 except for one
outlier point at 23 years old with a predicted value of around 4750.

``` r
birth_data |>   
  modelr::add_predictions(model_0) |>
  ggplot(aes(x = delwt, y = pred)) + geom_point() + 
  labs(
    title = "Model 0 Predictions of `delwt` Variable",
    x = "Mother's Weight at Delivery",
    y = "Predictions"
  )
```

<img src="p8105_hw_6_files/figure-gfm/unnamed-chunk-17-1.png" width="90%" />

The predicitions for mother’s delivery weight shows a strong positive
linear relationship. Like the plot directly above, the density and
spread of the predictions decrease as the x-axis (weight) variable
increases. Also, this plot is consistent with the residuals since it
also has the largest density and spread between 100-200 lbs. The two
points with the highest predicted value seem to be outliers.

**Other models to compare**

``` r
model_1 = lm(bwt ~ blength + gaweeks, data = birth_data)

model_1|> 
  broom::tidy() |> 
  knitr::kable(digits = 3)
```

| term        |  estimate | std.error | statistic | p.value |
|:------------|----------:|----------:|----------:|--------:|
| (Intercept) | -4347.667 |    97.958 |   -44.383 |       0 |
| blength     |   128.556 |     1.990 |    64.604 |       0 |
| gaweeks     |    27.047 |     1.718 |    15.744 |       0 |

``` r
model_2 = lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = birth_data)

model_2|> 
  broom::tidy() |> 
  knitr::kable(digits = 3)
```

| term                      |  estimate | std.error | statistic | p.value |
|:--------------------------|----------:|----------:|----------:|--------:|
| (Intercept)               |  -801.949 |  1102.308 |    -0.728 |   0.467 |
| bhead                     |   -16.598 |    34.092 |    -0.487 |   0.626 |
| blength                   |   -21.646 |    23.372 |    -0.926 |   0.354 |
| babysexmale               | -6374.868 |  1677.767 |    -3.800 |   0.000 |
| bhead:blength             |     3.324 |     0.713 |     4.666 |   0.000 |
| bhead:babysexmale         |   198.393 |    51.092 |     3.883 |   0.000 |
| blength:babysexmale       |   123.773 |    35.119 |     3.524 |   0.000 |
| bhead:blength:babysexmale |    -3.878 |     1.057 |    -3.670 |   0.000 |

**Cross Validation**

``` r
cv_df = 
  crossv_mc(birth_data, 100) 

cv_df =
  cv_df |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df |> 
  mutate(
    cv_mod_0  = map(train, \(df) lm(bwt ~ momage + delwt, data = df)),
    cv_mod_1  = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    cv_mod_2  = map(train, \(df) lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = df))) |> 
  mutate(
    rmse_model_0 = map2_dbl(cv_mod_0, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model_1 = map2_dbl(cv_mod_1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model_2 = map2_dbl(cv_mod_2, test, \(mod, df) rmse(model = mod, data = df)))

cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin() + 
  labs(
    title = "RMSE Distributions for each model",
    x = "Model Used",
    y = "RMSE"
  )
```

<img src="p8105_hw_6_files/figure-gfm/unnamed-chunk-20-1.png" width="90%" />

The root mean square error for each model after 5000 bootstraps is
pictured above in side-by-side violin plots. The hypothesized model has
much larger values and lacks the shape of the other two models. From
this, we can conclude that the hypothesized model is less optimal than
the other two models.
